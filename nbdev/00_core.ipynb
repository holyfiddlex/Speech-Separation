{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev.showdoc as literacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from speechsep.imports import *\n",
    "import speechsep.utils as utils\n",
    "import speechsep.plot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains most of the basic functions and spectrogram class types. To visualize the spectrograms we will also include a special color map since this makes it easier to notice differences in audio intensities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important things to remember are\n",
    "- How to create an AudioItem both from a numpy array and from file.\n",
    "- Creating a SpecImage and how the parameters influence the final result.\n",
    "- Basic SpecImage Visualizer (more indepth explanation here***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(load)\n",
    "def load_audio(fn, **kwargs):\n",
    "    return load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = Path(\"../data/AudioTest1.wav\")\n",
    "sig, sr = load_audio(fn)\n",
    "display(Audio(sig, rate=sr))\n",
    "\n",
    "test_eq(type(sig), np.ndarray)\n",
    "test_eq(type(sr), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AudioItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioBase():\n",
    "    def __init__(self,sig,_sr,fn=None):\n",
    "        store_attr(self, 'sig,_sr,fn')\n",
    "    def __repr__(self): display(Audio(self.sig, rate=self.sr)); return f'{self.__str__()}'\n",
    "    def __str__(self): return f'{self.fn}, {len(self.sig)/self.sr}secs at {self.sr} samples per second'\n",
    "    @delegates(Line2D)\n",
    "    def show(self, **kwargs): plt.plot(self.sig, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AudioItem(AudioBase):\n",
    "    @classmethod\n",
    "    def create(cls, fn, sr=None):\n",
    "        audio = cls(*load_audio(fn),fn)\n",
    "        if sr: audio.sr = sr\n",
    "        return audio\n",
    "    load_file = create\n",
    "    @property\n",
    "    def sr(self): return self._sr\n",
    "    @sr.setter\n",
    "    def sr(self, new_sr):\n",
    "        if self._sr != new_sr: self.sig = utils.Resample(new_sr)(self.sig, self.sr)\n",
    "        self._sr = new_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud1 = AudioItem.create(fn)\n",
    "\n",
    "test_eq(type(aud1), AudioItem)\n",
    "test_eq(aud1.sr, 22050)\n",
    "test_eq(aud1.fn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud2 = AudioItem.create(fn, sr=2205)\n",
    "\n",
    "test_eq(aud2.sr, 2205)\n",
    "test_eq(type(aud2.sig), np.ndarray)\n",
    "test_eq(type(aud2.sr), int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_property\n",
    "def duration(x:AudioItem):\n",
    "    return len(x.sig)/x.sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(type(aud1.duration), float)\n",
    "test_eq(round(aud1.duration), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud1.sr = 48000\n",
    "\n",
    "test_eq(aud1.sr, 48000)\n",
    "test_eq(round(aud1.duration), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpecImage\n",
    "Gives the template for the rest of the Spectrogram classes. There will be transforms to add mel-bin and decibels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SpecImage():\n",
    "    def __init__(self, data, sr, fn=None):\n",
    "        store_attr(self, 'data, sr, fn')\n",
    "        self._plt_params = {}\n",
    "    @property\n",
    "    def plt_params(self): return self._plt_params\n",
    "    @plt_params.setter\n",
    "    @delegates(plt.pcolormesh)\n",
    "    def plt_params(self, **kwargs):\n",
    "        self._plot = partial(plt.pcolormesh, **kwargs)\n",
    "        self._plt_params = dict(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Spectify(core.Transform):\n",
    "    def __init__(self, fftsize=512, win_mult=2, overlap=0.5, decibel=False, mel_bin=False):\n",
    "        store_attr(self, 'fftsize, win_mult, overlap, decibel, mel_bin')\n",
    "    def encodes(self, audio:AudioItem):\n",
    "        spec = utils.stft(audio.sig, self.fftsize, self.win_mult, self.overlap)\n",
    "        if self.decibel: pass #TODO Encode\n",
    "        if self.mel_bin: pass #TODO Encode\n",
    "        return SpecImage(spec, audio.sr, audio.fn)\n",
    "    def decodes(self, spec):\n",
    "        audio = utils.istft(spec.data, self.fftsize, self.win_mult, self.overlap)\n",
    "        if self.decibel: pass #TODO Decode\n",
    "        if self.mel_bin: pass #TODO Decode\n",
    "        return AudioItem(audio, spec.sr, spec.fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioItem.load_file(fn)\n",
    "Audio2Spec = Spectify()\n",
    "spec = Audio2Spec(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(type(spec), SpecImage)\n",
    "test_eq(type(spec.data), np.ndarray)\n",
    "test_eq(spec.fn, fn)\n",
    "test_eq(spec.sr, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "@delegates(plot.setup_graph)\n",
    "def show(x:SpecImage, ctx=None, **kwargs):\n",
    "    plot.setup_graph(**kwargs)\n",
    "    plt.pcolormesh(abs(x.data[:x.data.shape[0]//2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.show(title='one two', x_label='time', y_label='frequency', fig_size = [12,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_r = Audio2Spec.decodes(spec)\n",
    "audio_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(type(audio_r), AudioItem)\n",
    "test_eq(type(audio_r.sig), np.ndarray)\n",
    "test_eq(audio_r.sr, 22050)\n",
    "test_eq(audio_r.fn, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_clsmthd\n",
    "@delegates(to=Spectify)\n",
    "def create(cls:SpecImage, fn, sr=None, **kwargs):\n",
    "    #Open an `Audio` from path `fn`\n",
    "    if isinstance(fn,(Path,str)): return cls.create(AudioItem.create(fn,sr))\n",
    "    elif isinstance(fn,AudioItem): return Spectify(**kwargs)(fn)\n",
    "    raise ValueError('fn must be AudioItem, Path or str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = SpecImage.create(fn)\n",
    "spec.show(fig_size=[12,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MaskBase():\n",
    "    def __init__(self, data):\n",
    "        store_attr(self, 'data')\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    def __mult__(self, spec):\n",
    "        raise NotImplemented\n",
    "    @classmethod\n",
    "    def create(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
