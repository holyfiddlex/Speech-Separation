{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev.showdoc as literacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from speechsep.imports import *\n",
    "import speechsep.utils as utils\n",
    "import speechsep.plot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains most of the basic functions and spectrogram class types. To visualize the spectrograms we will also include a special color map since this makes it easier to notice differences in audio intensities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important things to remember are\n",
    "- How to create an AudioItem both from a numpy array and from file.\n",
    "- Creating a SpecImage and how the parameters influence the final result.\n",
    "- Basic SpecImage Visualizer (more indepth explanation here***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(load)\n",
    "def load_audio(fn, **kwargs):\n",
    "    return load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = Path(\"../data/AudioTest1.wav\")\n",
    "sig, sr = load_audio(fn)\n",
    "display(Audio(sig, rate=sr))\n",
    "\n",
    "test_eq(type(sig), np.ndarray)\n",
    "test_eq(type(sr), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## AudioItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class AudioItem():\n",
    "    def __init__(self, filename=None, signal=None, sample_rate=None):\n",
    "        self.fn = filename\n",
    "        if signal is None         : self.sig, self._sr = load_audio(self.fn)\n",
    "        else                      : self.sig, self._sr = signal, sample_rate\n",
    "        if sample_rate:\n",
    "            self.sr = sample_rate\n",
    "        elif self.sr is None:\n",
    "            raise ValueError('sample_rate must be calculated or given')\n",
    "    def __repr__(self):\n",
    "        display(Audio(self.sig, rate=self.sr))\n",
    "        return f'{self.__str__()}'\n",
    "    def __str__(self):\n",
    "        return f'{self.fn}, {len(self.sig)/self.sr}secs at {self.sr} samples per second'\n",
    "    @delegates(Line2D)\n",
    "    def show(self, **kwargs):\n",
    "        plt.plot(self.sig, **kwargs)\n",
    "    @property\n",
    "    def sr(self): return self._sr\n",
    "    @sr.setter\n",
    "    def sr(self, new_sr):\n",
    "        if self._sr != new_sr:\n",
    "            self.sig = utils.Resample(new_sr)(self.sig, self.sr)\n",
    "        self._sr = new_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio = AudioItem(fn)\n",
    "audio.show()\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio.sr = audio.sr//10\n",
    "audio.show()\n",
    "audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class toSpec(core.Transform):\n",
    "    def __init__(self, fftsize=512, win_mult=2, overlap=0.5, freq='linear', amp='linear'):\n",
    "        self.fftsize = fftsize\n",
    "        self.win_mult = win_mult\n",
    "        self.overlap = overlap\n",
    "        self.freq = freq\n",
    "        self.amp = amp\n",
    "    def encodes(self, audio:AudioItem):\n",
    "        spec = utils.stft(audio.sig, self.fftsize, self.win_mult, self.overlap)\n",
    "        return SpecBase(spec, audio.sr, audio.fn)\n",
    "    def decodes(self, spec):\n",
    "        audio = utils.istft(spec.data, self.fftsize, self.win_mult, self.overlap)\n",
    "        return AudioItem(spec.fn, audio, spec.sr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SpecBase():\n",
    "    def __init__(self, spec, sr, fn=None):\n",
    "        self.data = spec\n",
    "        self.sr = sr\n",
    "        self.fn = fn\n",
    "        self._plt_params = {}\n",
    "    @delegates(plot.setup_graph)\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        plot.setup_graph(**kwargs)\n",
    "        plt.pcolormesh(abs(spec.data[:spec.data.shape[0]//2]))\n",
    "    @property\n",
    "    def plt_params(self): return self._plt_params\n",
    "    @plt_params.setter\n",
    "    @delegates(plt.pcolormesh)\n",
    "    def plt_params(self, **kwargs):\n",
    "        self._plot = partial(plt.pcolormesh, **kwargs)\n",
    "        self._plt_params = dict(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @delegates(toSpec)\n",
    "    @classmethod\n",
    "    def create(cls, fn, sr=None, name=None, **kwargs):\n",
    "        \"Open an `Audio` from path `fn`\"\n",
    "        if isinstance(fn,(Path,str)): return cls.create(AudioItem(fn, sr), name=name)\n",
    "        elif isinstance(fn,AudioItem): return toSpec(**kwargs)(fn)\n",
    "        elif isinstance(fn,np.ndarray): return cls(fn, sr, name)\n",
    "        raise ValueError('fn must be ndarray, AudioItem or Path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioItem(fn)\n",
    "spec = toSpec()(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.show(fig_size = [12,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
