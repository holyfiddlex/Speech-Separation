{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from speechsep.imports import *\n",
    "from speechsep.plot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AudioBase\n",
    "The current base class for audio which is used for mono and multi-channel audio types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ResampleSignal(sr_new):\n",
    "    def _inner(sig, sr):\n",
    "        '''Resample using faster polyphase technique and avoiding FFT computation. Taken from FastaiAudio by LimeAI'''\n",
    "        if(sr == sr_new): return sig\n",
    "        sr_gcd = math.gcd(sr, sr_new)\n",
    "        resampled = resample_poly(sig, int(sr_new/sr_gcd), int(sr/sr_gcd), axis=-1)\n",
    "        #resampled = resampled.astype(np.float32)\n",
    "        return resampled\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AudioBase():\n",
    "    _show_args={}\n",
    "    def __init__(self,sig,_sr,fn=None):\n",
    "        store_attr(self, 'sig,_sr,fn')\n",
    "        self.data = self.sig\n",
    "    def __repr__(self): self.listen(); return f'{self.__str__()}'\n",
    "    def __str__(self): return f'{self.fn}, {self.duration}secs at {self.sr} samples per second'\n",
    "    def listen(self): display(Audio(self.sig, rate=self.sr))\n",
    "    @property\n",
    "    def sr(self): return self._sr\n",
    "    @sr.setter\n",
    "    def sr(self, new_sr):\n",
    "        if self._sr != new_sr: self.sig = ResampleSignal(new_sr)(self.sig, self.sr)\n",
    "        self._sr = new_sr\n",
    "    @property\n",
    "    def duration(self): return len(self.sig)/self.sr\n",
    "    @delegates(Line2D)\n",
    "    def show(self, ctx=None, **kwargs): return show_audio(self, ctx=ctx, **merge(self._show_args, kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpecBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SpecBase():\n",
    "    _show_args={}\n",
    "    def __init__(self, data, sr, fn=None):\n",
    "        store_attr(self, 'data, sr, fn')\n",
    "        self._plt_params = {}\n",
    "    @property\n",
    "    def plt_params(self): return self._plt_params\n",
    "    @plt_params.setter\n",
    "    @delegates(plt.pcolormesh)\n",
    "    def plt_params(self, **kwargs):\n",
    "        self._plot = partial(plt.pcolormesh, **kwargs)\n",
    "        self._plt_params = dict(**kwargs)\n",
    "    @delegates(setup_graph)\n",
    "    def show(self, ctx=None, **kwargs): return show_spec(self, ctx=ctx, **merge(self._show_args, kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x:(AudioBase, SpecBase), y, samples, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):\n",
    "    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), rows=rows, cols=cols, figsize=figsize)\n",
    "    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    return ctxs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
