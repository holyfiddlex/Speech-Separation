{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from speechsep.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AudioBase\n",
    "The current base class for audio which is used for mono and multi-channel audio types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ResampleSignal(sr_new):\n",
    "    def _inner(sig, sr):\n",
    "        '''Resample using faster polyphase technique and avoiding FFT computation. Taken from FastaiAudio by LimeAI'''\n",
    "        if(sr == sr_new): return sig\n",
    "        sr_gcd = math.gcd(sr, sr_new)\n",
    "        resampled = resample_poly(sig, int(sr_new/sr_gcd), int(sr/sr_gcd), axis=-1)\n",
    "        #resampled = resampled.astype(np.float32)\n",
    "        return resampled\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AudioBase():\n",
    "    _show_args={}\n",
    "    def __init__(self,sig,_sr,fn=None):\n",
    "        store_attr(self, 'sig,_sr,fn')\n",
    "        self.data = self.sig\n",
    "    def __repr__(self): self.listen(); return f'{self.__str__()}'\n",
    "    def __str__(self): return f'{self.fn}, {self.duration}secs at {self.sr} samples per second'\n",
    "    def listen(self): display(Audio(self.sig, rate=self.sr))\n",
    "    @property\n",
    "    def sr(self): return self._sr\n",
    "    @sr.setter\n",
    "    def sr(self, new_sr):\n",
    "        if self._sr != new_sr: self.sig = ResampleSignal(new_sr)(self.sig, self.sr)\n",
    "        self._sr = new_sr\n",
    "    @property\n",
    "    def duration(self): return len(self.sig)/self.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpecBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SpecBase():\n",
    "    _show_args={}\n",
    "    def __init__(self, data, sr, fn=None):\n",
    "        store_attr(self, 'data, sr, fn')\n",
    "        self._plt_params = {}\n",
    "    @property\n",
    "    def plt_params(self): return self._plt_params\n",
    "    @plt_params.setter\n",
    "    @delegates(plt.pcolormesh)\n",
    "    def plt_params(self, **kwargs):\n",
    "        self._plot = partial(plt.pcolormesh, **kwargs)\n",
    "        self._plt_params = dict(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _check_len(audio_list):\n",
    "    lengths = set([len(audio) for audio in audio_list])\n",
    "    if len(lengths) > 1: ValueError(\"To generate Masks make sure that the length of files are equal.\")\n",
    "    return lengths.pop()\n",
    "\n",
    "def join_audio(audio_list, cls=AudioBase):\n",
    "    if isinstance(audio_list[0], cls): np_list = [audio.data for audio in audio_list]\n",
    "    mix = np.zeros(_check_len(np_list))\n",
    "    for aud in np_list:\n",
    "        mix+=aud\n",
    "    mix /= len(np_list)\n",
    "    return cls(mix, audio_list[0].sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MaskBase():\n",
    "    def __init__(self, data):\n",
    "        store_attr(self, 'data')\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    @classmethod\n",
    "    def create(cls, audios):\n",
    "        self.adjust(audios)\n",
    "        joined = join_audios(audios)\n",
    "        return [cls(self.generate(joined, aud)) for aud in audios]\n",
    "    def adjust(self, audios):\n",
    "        pass\n",
    "    def __mult__(self, spec):\n",
    "        raise NotImplementedError('This function needs to be implemented before use')\n",
    "    def generate(self, joined, aud):\n",
    "        raise NotImplementedError('This function needs to be implemented before use')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
