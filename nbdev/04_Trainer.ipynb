{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm.auto import tqdm\n",
    "from speechsep.core import *\n",
    "from speechsep.masks import *\n",
    "from speechsep.pipe import *\n",
    "from speechsep.utils import *\n",
    "from speechsep.data import *\n",
    "from speechsep.imports import *\n",
    "from speechsep.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#fn = Path(\"../../data/clips/\")\n",
    "fn = Path(\"../../datawav/\")\n",
    "pipe = AudioPipe(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tensorify(Transform):\n",
    "    def encodes(self, x, cuda=True):\n",
    "        tnsr = complex2real(x.data) if hasattr(x, \"data\") else complex2real(x)\n",
    "        return torch.FloatTensor(tnsr).cuda() if cuda else torch.FloatTensor(tnsr)\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    @delegates(AudioPipe)\n",
    "    def __init__(self, fn, **kwargs):\n",
    "        self.fn = fn\n",
    "        self.pipe = AudioPipe(fn, **kwargs)\n",
    "        self.n_samples = len(get_audio_files(fn))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.pipe(index)\n",
    "        x,y = Tensorify()(x),Tensorify()(y)\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def loss_func(x,y):\n",
    "    loss = nn.MSELoss()\n",
    "    min_loss = min([loss(x[i], y[i]) for i in range(len(x))])\n",
    "    return min_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bs = 16\n",
    "shuffle=True\n",
    "workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataset.py\", line 257, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"<ipython-input-6-f5412aa2eca5>\", line 16, in __getitem__\n    x,y = Tensorify()(x),Tensorify()(y)\n  File \"/home/jupyter/fastcore/fastcore/transform.py\", line 61, in __call__\n    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n  File \"/home/jupyter/fastcore/fastcore/transform.py\", line 69, in _call\n    if self.use_as_item or not is_listy(x): return self._do_call(f, x, **kwargs)\n  File \"/home/jupyter/fastcore/fastcore/transform.py\", line 74, in _do_call\n    return x if f is None else retain_type(f(x, **kwargs), x, f.returns_none(x))\n  File \"/home/jupyter/fastcore/fastcore/dispatch.py\", line 98, in __call__\n    return f(*args, **kwargs)\n  File \"<ipython-input-6-f5412aa2eca5>\", line 5, in encodes\n    return torch.FloatTensor(tnsr).cuda() if cuda else torch.cuda.FloatTensor(tnsr)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 191, in _lazy_init\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5bbba25e5e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataset.py\", line 257, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"<ipython-input-6-f5412aa2eca5>\", line 16, in __getitem__\n    x,y = Tensorify()(x),Tensorify()(y)\n  File \"/home/jupyter/fastcore/fastcore/transform.py\", line 61, in __call__\n    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n  File \"/home/jupyter/fastcore/fastcore/transform.py\", line 69, in _call\n    if self.use_as_item or not is_listy(x): return self._do_call(f, x, **kwargs)\n  File \"/home/jupyter/fastcore/fastcore/transform.py\", line 74, in _do_call\n    return x if f is None else retain_type(f(x, **kwargs), x, f.returns_none(x))\n  File \"/home/jupyter/fastcore/fastcore/dispatch.py\", line 98, in __call__\n    return f(*args, **kwargs)\n  File \"<ipython-input-6-f5412aa2eca5>\", line 5, in encodes\n    return torch.FloatTensor(tnsr).cuda() if cuda else torch.cuda.FloatTensor(tnsr)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 191, in _lazy_init\n    \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\nRuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "dataset = AudioDataset(fn)\n",
    "n = len(dataset)\n",
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(dataset, [50, 25, n-75])\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "valid_dl = DataLoader(dataset=valid_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "\n",
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model = U_Net(img_ch=2, output_ch=4).cuda()\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "n_epochs = 1\n",
    "n_samples = len(train_dl.dataset)\n",
    "n_iter = math.ceil(n_samples/bs)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (xb, yb) in tqdm(enumerate(train_dl)):\n",
    "        print(1)\n",
    "        out = model(xb)\n",
    "        print(2)\n",
    "        mask1 = MaskcIRM(out[:,:2,:,:])\n",
    "        mask2 = MaskcIRM(out[:,2:,:,:])\n",
    "        sep = mask1*xb, mask2*xb\n",
    "        loss = loss_func(sep, yb)\n",
    "        print(3)\n",
    "        #if (i+1)%5==0:\n",
    "        #    print(f'epoch {epoch}: step {(i+1)/n_iter}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(4)\n",
    "    print(f\"epoch {epoch+1} Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
