{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm.auto import tqdm\n",
    "from speechsep.core import *\n",
    "from speechsep.masks import *\n",
    "from speechsep.pipe import *\n",
    "from speechsep.utils import *\n",
    "from speechsep.data import *\n",
    "from speechsep.imports import *\n",
    "from speechsep.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#fn = Path(\"../../data/clips/\")\n",
    "fn = Path(\"../../datawav/\")\n",
    "pipe = AudioPipe(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tensorify(Transform):\n",
    "    def encodes(self, x, cuda=True):\n",
    "        tnsr = complex2real(x.data) if hasattr(x, \"data\") else complex2real(x)\n",
    "        return torch.cuda.FloatTensor(tnsr)\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    @delegates(AudioPipe)\n",
    "    def __init__(self, fn, **kwargs):\n",
    "        self.fn = fn\n",
    "        self.pipe = AudioPipe(fn, **kwargs)\n",
    "        self.n_samples = len(get_audio_files(fn))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.pipe(index)\n",
    "        x,y = Tensorify()(x),Tensorify()(y)\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def loss_func(x,y):\n",
    "    if (x[0]!=x[0]).any() or (x[1]!=x[1]).any():\n",
    "        raise AssertionError(f'Loss x contained nan')\n",
    "    if (y[0]!=y[0]).any() or (y[1]!=y[1]).any():\n",
    "        raise AssertionError(f'Loss y contained nan')\n",
    "    loss = nn.MSELoss()\n",
    "    min_loss = min(loss(x[0],y[0]) + loss(x[1],y[1]), loss(x[0],y[1]) + loss(x[1],y[0]))\n",
    "    if (min_loss!=min_loss).any():\n",
    "        raise AssertionError(f'Loss returned contained nan')\n",
    "    return min_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bs = 2\n",
    "shuffle=True\n",
    "workers=0\n",
    "seed=42\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dataset = AudioDataset(fn)\n",
    "n = len(dataset)\n",
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(dataset, [1000, 500, n-1500])\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "valid_dl = DataLoader(dataset=valid_ds, batch_size=1, shuffle=shuffle, num_workers=workers)\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=1, shuffle=shuffle, num_workers=workers)\n",
    "\n",
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model = U_Net(img_ch=2, output_ch=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "n_epochs = 8\n",
    "n_samples = len(train_dl.dataset)\n",
    "n_iter = math.ceil(n_samples/bs)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7e2fc166ac4f9aa953a2fe24fc644e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 212992 NANS FOUND DECIBELIFY\n",
      "WARNING 212992 NANS FOUND DECIBELIFY\n",
      "WARNING 212992 NANS FOUND DECIBELIFY\n",
      "WARNING 212992 NANS FOUND DECIBELIFY\n",
      "\n",
      "epoch 1 Finished, saved model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1daebc04b4434c27b21ea54d9b111022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 212992 NANS FOUND DECIBELIFY\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (xb, yb) in tqdm(enumerate(train_dl)):\n",
    "        if (xb!=xb).any():\n",
    "            raise AssertionError(f'Input contained nan during epoch {epoch} and step {i}')\n",
    "        out = model(xb)\n",
    "        if (out!=out).any():\n",
    "            raise AssertionError(f'Output contained nan during epoch {epoch} and step {i}')\n",
    "        mask1 = MaskBinary(out[:,:1,:,:])\n",
    "        mask2 = MaskBinary(out[:,1:,:,:])\n",
    "        sep = mask1*xb, mask2*xb\n",
    "        loss = loss_func(sep, yb)\n",
    "\n",
    "        #if (i+1)%5==0:\n",
    "        #    print(f'epoch {epoch}: step {(i+1)/n_iter}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    torch.save(model.state_dict(), f\"../models/unet_{epoch+1}_complex\")\n",
    "    print(f\"epoch {epoch+1} Finished, saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afsdfafds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model.cpu()\n",
    "model.eval()\n",
    "for i, (xb, yb) in tqdm(enumerate(valid_dl)):\n",
    "    xb,yb = xb.detach().cpu(), [yb[i].detach().cpu() for i in range(2)]\n",
    "    out = model(xb)\n",
    "    mask1 = MaskBinary(out[:,:1,:,:])\n",
    "    mask2 = MaskBinary(out[:,1:,:,:])\n",
    "    \n",
    "    sep = mask1*xb, mask2*xb\n",
    "    sep = [sep[i].detach().cpu().squeeze() for i in range(len(sep))]\n",
    "    sep = [real2complex(sep[i]) for i in range(len(sep))]\n",
    "    spec1, spec2 = SpecImage(sep[0], 22050), SpecImage(sep[1], 22050)\n",
    "    \n",
    "    spec_mixed = xb.detach().cpu().squeeze()\n",
    "    spec_mixed = real2complex(spec_mixed)\n",
    "    spec_mixed = SpecImage(spec_mixed, 22050)\n",
    "    \n",
    "    spec1.show()\n",
    "    spec2.show()\n",
    "    spec_mixed.show()\n",
    "    \n",
    "    print(spec1.data[0][0])\n",
    "    spec1 = Decibelify().decode(spec1)\n",
    "    spec2 = Decibelify().decode(spec2)\n",
    "    spec_mixed = Decibelify().decode(spec_mixed)\n",
    "    \n",
    "    print(spec1.data[0][0])\n",
    "    audio1 = Spectify().decode(spec1)\n",
    "    audio2 = Spectify().decode(spec2)\n",
    "    audio_mixed = Spectify().decode(spec_mixed)\n",
    "    \n",
    "    print(audio1.data[0])\n",
    "    audio1.listen()\n",
    "    audio2.listen()\n",
    "    audio_mixed.listen()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "state = torch.load('../models/unet_1_binary')\n",
    "model.load_state_dict(state)\n",
    "model.cpu()\n",
    "model.eval()\n",
    "for i, (xb, yb) in tqdm(enumerate(valid_dl)):\n",
    "    xb,yb = xb.detach().cpu(), [yb[i].detach().cpu() for i in range(2)]\n",
    "    out = model(xb)\n",
    "    mask1 = MaskBinary(out[:,:1,:,:])\n",
    "    mask2 = MaskBinary(out[:,1:,:,:])\n",
    "    \n",
    "    sep = mask1*xb, mask2*xb\n",
    "    sep = [sep[i].detach().cpu().squeeze() for i in range(len(sep))]\n",
    "    sep = [real2complex(sep[i]) for i in range(len(sep))]\n",
    "    spec1, spec2 = SpecImage(sep[0], 22050), SpecImage(sep[1], 22050)\n",
    "    \n",
    "    spec_mixed = xb.detach().cpu().squeeze()\n",
    "    spec_mixed = real2complex(spec_mixed)\n",
    "    spec_mixed = SpecImage(spec_mixed, 22050)\n",
    "    \n",
    "    spec1.show()\n",
    "    spec2.show()\n",
    "    spec_mixed.show()\n",
    "    \n",
    "    print(spec1.data[0][0])\n",
    "    spec1 = Decibelify().decode(spec1)\n",
    "    spec2 = Decibelify().decode(spec2)\n",
    "    spec_mixed = Decibelify().decode(spec_mixed)\n",
    "    \n",
    "    print(spec1.data[0][0])\n",
    "    audio1 = Spectify().decode(spec1)\n",
    "    audio2 = Spectify().decode(spec2)\n",
    "    audio_mixed = Spectify().decode(spec_mixed)\n",
    "    \n",
    "    print(audio1.data[0])\n",
    "    audio1.listen()\n",
    "    audio2.listen()\n",
    "    audio_mixed.listen()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
