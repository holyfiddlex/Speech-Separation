{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tqdm.auto import tqdm\n",
    "from speechsep.core import *\n",
    "from speechsep.masks import *\n",
    "from speechsep.pipe import *\n",
    "from speechsep.utils import *\n",
    "from speechsep.data import *\n",
    "from speechsep.imports import *\n",
    "from speechsep.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#fn = Path(\"../../data/clips/\")\n",
    "fn = Path(\"../../datawav/\")\n",
    "pipe = AudioPipe(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tensorify(Transform):\n",
    "    def encodes(self, x, cuda=True):\n",
    "        tnsr = complex2real(x.data) if hasattr(x, \"data\") else complex2real(x)\n",
    "        return torch.cuda.FloatTensor(tnsr)\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    @delegates(AudioPipe)\n",
    "    def __init__(self, fn, **kwargs):\n",
    "        self.fn = fn\n",
    "        self.pipe = AudioPipe(fn, **kwargs)\n",
    "        self.n_samples = len(get_audio_files(fn))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.pipe(index)\n",
    "        x,y = Tensorify()(x),Tensorify()(y)\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def loss_func(x,y):\n",
    "    loss = nn.MSELoss()\n",
    "    min_loss = min([loss(x[i], y[i]) for i in range(len(x))])\n",
    "    return min_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bs = 4\n",
    "shuffle=True\n",
    "workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "dataset = AudioDataset(fn)\n",
    "n = len(dataset)\n",
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(dataset, [5000, 2500, n-7500])\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "valid_dl = DataLoader(dataset=valid_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "test_dl = DataLoader(dataset=test_ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "\n",
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model = U_Net(img_ch=2, output_ch=4).cuda()\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "n_epochs = 10\n",
    "n_samples = len(train_dl.dataset)\n",
    "n_iter = math.ceil(n_samples/bs)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46005aa351eb44ccaaa96a0f5b42684a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (xb, yb) in tqdm(enumerate(train_dl)):\n",
    "        out = model(xb)\n",
    "        mask1 = MaskcIRM(out[:,:2,:,:])\n",
    "        mask2 = MaskcIRM(out[:,2:,:,:])\n",
    "        sep = mask1*xb, mask2*xb\n",
    "        loss = loss_func(sep, yb)\n",
    "\n",
    "        #if (i+1)%5==0:\n",
    "        #    print(f'epoch {epoch}: step {(i+1)/n_iter}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    torch.save(model.state_dict(), f\"../models/unet_{epoch+1}\")\n",
    "    print(f\"epoch {epoch+1} Finished, saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
