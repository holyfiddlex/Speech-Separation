# AUTOGENERATED! DO NOT EDIT! File to edit: nbdev/04_Trainer.ipynb (unless otherwise specified).

__all__ = ['fn', 'pipe', 'Tensorify', 'AudioDataset', 'loss_func', 'bs', 'shuffle', 'workers', 'dataset', 'dataloader',
           'dataiter', 'data', 'model', 'n_epochs', 'n_samples', 'n_iter', 'optimizer']

# Cell
from .core import *
from .masks import *
from .pipe import *
from .utils import *
from .data import *
from .imports import *
from .models import *

# Cell
from torch.utils.data import Dataset, DataLoader
import torch
import torchvision

# Cell
fn = Path("../data/esc50_sample/")
pipe = AudioPipe(fn)

# Cell
class Tensorify(Transform):
    def encodes(self, x):
        tnsr = complex2real(x.data) if hasattr(x, "data") else complex2real(x)
        return torch.FloatTensor(tnsr)

class AudioDataset(Dataset):
    @delegates(AudioPipe)
    def __init__(self, fn, **kwargs):
        self.fn = fn
        self.pipe = AudioPipe(fn, **kwargs)
        self.n_samples = len(get_audio_files(fn))

    def __getitem__(self, index):
        x,y = self.pipe(index)
        x,y = Tensorify()(x),Tensorify()(y)
        return x,y

    def __len__(self):
        return self.n_samples

# Cell
def loss_func(x,y):
    loss = nn.MSELoss()
    min_loss = min([loss(x[i], y[i]) for i in range(len(x))])
    return min_loss

# Cell
bs = 1
shuffle=True
workers=2

# Cell
dataset = AudioDataset(fn)
dataloader = DataLoader(dataset=dataset, batch_size=bs, shuffle=shuffle, num_workers=workers)

dataiter = iter(dataloader)
data = dataiter.next()
data;

# Cell
model = U_Net(img_ch=2, output_ch=4)
model.train();

# Cell
n_epochs = 1
n_samples = len(dataset)
n_iter = math.ceil(n_samples/bs)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Cell
for epoch in range(n_epochs):
    for i, (xb, yb) in enumerate(dataloader):
        out = model(xb)
        mask1 = MaskcIRM(out[:,:2,:,:])
        mask2 = MaskcIRM(out[:,2:,:,:])
        sep = mask1*xb, mask2*xb
        loss = loss_func(sep, yb)
        if (i+1)%5==0:
            print(f'epoch {epoch}: step {(i+1)/n_iter}')
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        print("first step")
        break