#AUTOGENERATED! DO NOT EDIT! File to edit: dev/00_core.ipynb (unless otherwise specified).

__all__ = ['load_audio', 'ResampleSignal', 'AudioBase', 'AudioMono', 'duration', 'SpecImage', 'Spectify', 'show',
           'MaskBase', 'MaskBinary', 'Resample', 'Clip', 'ArrayAudioBase', 'TensorAudio', 'encodes', 'audio2tensor',
           'show_audio', 'hear_audio']

#Cell
from .imports import *
from .utils import *
from .plot import *

#Cell
@delegates(load)
def load_audio(fn, **kwargs):
    return load(fn)

#Cell
def ResampleSignal(sr_new):
    def _inner(sig, sr):
        '''Resample using faster polyphase technique and avoiding FFT computation. Taken from FastaiAudio by LimeAI'''
        if(sr == sr_new): return sig
        sr_gcd = math.gcd(sr, sr_new)
        resampled = resample_poly(sig, int(sr_new/sr_gcd), int(sr/sr_gcd), axis=-1)
        #resampled = resampled.astype(np.float32)
        return resampled
    return _inner

#Cell
class AudioBase():
    _show_args={}
    def __init__(self,sig,_sr,fn=None):
        store_attr(self, 'sig,_sr,fn')
    def __repr__(self): self.listen(); return f'{self.__str__()}'
    def __str__(self): return f'{self.fn}, {self.duration}secs at {self.sr} samples per second'
    @delegates(Line2D)
    def show(self, ctx=None, **kwargs):
        return show_audio(self, ctx=ctx, **merge(self._show_args, kwargs))
    def listen(self): display(Audio(self.sig, rate=self.sr))
    @property
    def sr(self): return self._sr
    @sr.setter
    def sr(self, new_sr):
        if self._sr != new_sr: self.sig = ResampleSignal(new_sr)(self.sig, self.sr)
        self._sr = new_sr
    @property
    def duration(self): return len(self.sig)/self.sr

#Cell
class AudioMono(AudioBase):
    _show_args={}
    @classmethod
    def create(cls, fn, sr=None):
        audio = cls(*load_audio(fn),fn)
        if sr: audio.sr = sr
        return audio
    load_file = create

#Cell
@patch_property
def duration(x:AudioMono):
    return len(x.sig)/x.sr

#Cell
class SpecImage():
    def __init__(self, data, sr, fn=None):
        store_attr(self, 'data, sr, fn')
        self._plt_params = {}
    @property
    def plt_params(self): return self._plt_params
    @plt_params.setter
    @delegates(plt.pcolormesh)
    def plt_params(self, **kwargs):
        self._plot = partial(plt.pcolormesh, **kwargs)
        self._plt_params = dict(**kwargs)

#Cell
class Spectify(Transform):
    def __init__(self, fftsize=512, win_mult=2, overlap=0.5, decibel=False, mel_bin=False):
        store_attr(self, 'fftsize, win_mult, overlap, decibel, mel_bin')
    def encodes(self, audio:AudioMono):
        spec = stft(audio.sig, self.fftsize, self.win_mult, self.overlap)
        if self.decibel: pass #TODO Encode
        if self.mel_bin: pass #TODO Encode
        return SpecImage(spec, audio.sr, audio.fn)
    def decodes(self, spec):
        audio = istft(spec.data, self.fftsize, self.win_mult, self.overlap)
        if self.decibel: pass #TODO Decode
        if self.mel_bin: pass #TODO Decode
        return AudioMono(audio, spec.sr, spec.fn)

#Cell
@patch
@delegates(setup_graph)
def show(x:SpecImage, ctx=None, **kwargs):
    setup_graph(**kwargs)
    plt.pcolormesh(abs(x.data[:x.data.shape[0]//2]))

#Cell
class MaskBase():
    def __init__(self, data):
        store_attr(self, 'data')
    @property
    def shape(self):
        return self.data.shape
    @classmethod
    def create(cls, audios):
        self.adjust(audios)
        joined = join_audios(audios)
        return [cls(self.generate(joined, aud)) for aud in audios]
    def adjust(self, audios):
        pass
    def __mult__(self, spec):
        raise NotImplementedError('This function needs to be implemented before use')
    def generate(self, joined, aud):
        raise NotImplementedError('This function needs to be implemented before use')

#Cell
class MaskBinary(MaskBase):
    def __mult__(self, spec): pass
    def __generate__(self, joined, aud): pass

#Cell
class Resample(Transform):
    def __init__(self, sr): self.sr = sr
    def encodes(self, x:AudioBase): x.sr = self.sr; return x

#Cell
class Clip(Transform):
    def __init__(self, time): self.time = time
    def encodes(self, x:AudioBase):
        new_sig_len = int(self.time*x.sr)
        diff = abs(len(x.sig) - new_sig_len)
        if len(x.sig) <= new_sig_len:
            x.sig = np.pad(x.sig, (0,diff), 'constant', constant_values=(0, 0))
        else:
            x.sig = x.sig[:new_sig_len]
        return x

#Cell
class ArrayAudioBase(ArrayBase):
    _show_args = {}
    def show(self, **kwargs):
        return show_audio(self, ctx=ctx, **{**self._show_args, **kwargs})

class TensorAudio(TensorBase):
    _show_args = ArrayAudioBase._show_args
    def show(self, ctx=None, **kwargs):
        return show_audio(self, ctx=ctx, **{**self._show_args, **kwargs})

#Cell
AudioMono._tensor_cls = TensorAudio
@ToTensor
def encodes(self, o:AudioBase): return o._tensor_cls(audio2tensor(o))

def audio2tensor(aud:AudioBase): return Tensor(aud.sig)

#Cell
@typedispatch
def show_batch(x:AudioBase, y, samples, ctxs=None, max_n=10, rows=None, cols=None, figsize=None, **kwargs):
    if ctxs is None: ctxs = get_grid(min(len(samples), max_n), rows=rows, cols=cols, figsize=figsize)
    ctxs = show_batch[object](x, y, samples, ctxs=ctxs, max_n=max_n, **kwargs)
    return ctxs

def show_audio(aud, ax=None, pltsize=None, title=None, ctx=None, **kwargs):
    ax = ifnone(ax,ctx)
    if ax is None: _,ax = plt.subplots(figsize=pltsize)
    if isinstance(aud, AudioBase): aud = aud.sig;
    elif not isinstance(aud,np.ndarray): aud=array(aud)
    ax.plot(aud, **kwargs)
    if title is not None: ax.set_title(title)
    ax.axis('off')
    return ax

def hear_audio(aud, sr=48000, **kwargs):
    if isinstance(aud, AudioBase): display(Audio(aud.sig, rate=aud.sr))
    else:                          display(Audio(aud, rate=sr))